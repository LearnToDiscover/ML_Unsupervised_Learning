<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><title>Machine Learning - Unsupervised: Clustering Introduction</title><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="stylesheet" type="text/css" href="assets/styles.css"><script src="assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png"><link rel="manifest" href="site.webmanifest"><link rel="mask-icon" href="safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" content="#ffffff"></head><body>
    <header id="top" class="navbar navbar-expand-md navbar-light bg-white top-nav l2d"><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-6">
      <div class="large-logo">
        <img alt="l2d" src="assets/images/l2d-logo.svg"></div>
    </div>
    <div class="selector-container">


      <div class="dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Learner View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1"><li><button class="dropdown-item" type="button" onclick="window.location.href='instructor/01-clustering-intro.html';">Instructor View</button></li>
        </ul></div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl navbar-light bg-white bottom-nav l2d" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="l2d" src="assets/images/l2d-logo-sm.svg"></div>
    <div class="lesson-title-md">
      Machine Learning - Unsupervised
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item">
          <span class="lesson-title">
            Machine Learning - Unsupervised
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="reference.html#glossary">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="profiles.html">Learner Profiles</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown"></ul></li>
      </ul></div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a class="btn btn-primary" href="aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div><!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Machine Learning - Unsupervised
</div>

<aside class="col-md-12 lesson-progress"><div style="width: 0%" class="percentage">
    0%
  </div>
  <div class="progress l2d">
    <div class="progress-bar l2d" role="progressbar" style="width: 0%" aria-valuenow="0" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar" style="display: flex">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle sticky-top" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner sticky-top">
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Learner View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="instructor/01-clustering-intro.html">Instructor View</a>
                      </div>
                    </div>
                  </div><!--/div.accordion-item-->
                </div><!--/div.accordion-flush-->
              </div><!--div.sidenav-view-selector -->
            </div><!--/div.col -->

            <hr></div><!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Setup</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlushcurrent">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-headingcurrent">
      <button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapsecurrent" aria-expanded="true" aria-controls="flush-collapsecurrent">
        <span class="visually-hidden">Current Chapter</span>
        <span class="current-chapter">
        1. Clustering Introduction
        </span>
      </button>
    </div><!--/div.accordion-header-->

    <div id="flush-collapsecurrent" class="accordion-collapse collapse show" aria-labelledby="flush-headingcurrent" data-bs-parent="#accordionFlushcurrent">
      <div class="accordion-body">
        <ul><li><a href="#example">Example</a></li>
<li><a href="#gaussian-mixture-models">Gaussian Mixture Models</a></li>
<li><a href="#work-through-example">Work Through Example</a></li>
<li><a href="#application-to-example-data">Application to Example Data</a></li>
<li><a href="#exercises">Exercises</a></li>
        </ul></div><!--/div.accordion-body-->
    </div><!--/div.accordion-collapse-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="02-clustering-image.html">2. Clustering Images</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="03-dimensionality.html">3. Dimensionality Reduction</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width"><div class="accordion accordion-flush resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul><li>
                        <a href="key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="reference.html#glossary">Glossary</a>
                      </li>
                      <li>
                        <a href="profiles.html">Learner Profiles</a>
                      </li>

                    </ul></div>
                </div>
              </div>
            </div>
            <hr class="half-width resources"><a href="aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none"><div class="d-grid gap-1">

            </div>
          </div><!-- /div.accordion -->
        </div><!-- /div.sidebar-inner -->
      </nav></div><!-- /div.sidebar -->
  </div><!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-instructor.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <nav class="lesson-content mx-md-4" aria-label="Previous and Next Chapter"><!-- content for small screens --><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="index.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="02-clustering-image.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="index.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Home
        </a>
        <a class="chapter-link float-end" href="02-clustering-image.html" rel="next">
          Next: Clustering Images...
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
      <hr></nav><main id="main-content" class="main-content"><div class="container lesson-content">
        <h1>Clustering Introduction</h1>
        <p>Last updated on 2025-01-27 |

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/01-clustering-intro.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>



        <div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>

        

<p><a href="https://drive.usercontent.google.com/u/1/uc?id=1o4rsr8av-DaGtNILCXNRLnkhCUfoipht&amp;export=download" class="external-link"><strong>Download
Chapter notebook (ipynb)</strong></a></p>
<p><a href="https://drive.usercontent.google.com/u/1/uc?id=1d25T9eqO1vbgIFzKNu3d7UeLSdFHW8i7&amp;export=download" class="external-link"><strong>Download
Chapter PDF</strong></a></p>
<p><a href="https://docs.google.com/forms/d/e/1FAIpQLSdr0capF7jloJhPH3Pki1B3LZoKOG16poOpuVJ7SL2LkwLHQA/viewform?pli=1" class="external-link"><span style="color: rgb(255, 0, 0);"><strong>Mandatory Lesson Feedback
Survey</strong></span></a></p>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul><li>How to search for multiple distributions in a dataset?</li>
<li>How to use Scikit-learn to perform clustering?</li>
<li>How is data labelled in unsupervised learning?</li>
<li>How can we score clustering predictions?</li>
</ul></div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul><li>Understanding Multiple Gaussian distributions in a dataset.</li>
<li>Demonstrating Scikit-learn functionality for Gaussian Mixture
Models.</li>
<li>Learning automated labelling of dataset.</li>
<li>Obtaining a basic quality score using a ground truth.</li>
</ul></div>
</div>
</div>
</div>
</div>
<br><p align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/skuOor8jjlU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</p>
<br><p align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/czt2rKrfIzw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</p>
<p><br></p>
<div id="prereq1" class="callout prereq">
<div class="callout-square">
<i class="callout-icon" data-feather="check"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Prerequisite</h3>
<div class="callout-content">
<ul><li><a href="https://learntodiscover.github.io/ML_supervised/01-classification_intro.html" class="external-link">Classification
Introduction</a></li>
<li><a href="https://learntodiscover.github.io/ML_supervised/02-improvement.html" class="external-link">Classification
Improvement</a></li>
</ul></div>
</div>
</div>
<div class="section level3">
<h3 id="import-functions"><strong>Import functions</strong><a class="anchor" aria-label="anchor" href="#import-functions"></a></h3>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> arange, asarray, linspace, zeros, c_, mgrid, meshgrid, array, dot, percentile</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> histogram, cumsum, around</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> vstack, sqrt, logspace, amin, amax, equal, invert, count_nonzero</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">from</span> numpy.random <span class="im">import</span> uniform, seed, randint, randn, multivariate_normal</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">from</span> matplotlib.pyplot <span class="im">import</span> subplots, scatter, xlabel, ylabel, axis, figure, colorbar, title, show</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="im">from</span> matplotlib.colors <span class="im">import</span> LogNorm</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="im">from</span> pandas <span class="im">import</span> read_csv</span></code></pre>
</div>
</div>
<section><h2 class="section-heading" id="example">Example<a class="anchor" aria-label="anchor" href="#example"></a></h2>
<hr class="half-width"><p>Import the patients data, scatter the data for Weight and Height and
get a summary statistics for both.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>df <span class="op">=</span> read_csv(<span class="st">"data/patients_data.csv"</span>)</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="co"># Weigth to kg and height to cm</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>pound_kg_conversion <span class="op">=</span> <span class="fl">0.45</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>inch_cm_conversion  <span class="op">=</span> <span class="fl">2.54</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>df[<span class="st">'Weight'</span>] <span class="op">=</span> pound_kg_conversion<span class="op">*</span>df[<span class="st">'Weight'</span>]</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>df[<span class="st">'Height'</span>] <span class="op">=</span> inch_cm_conversion <span class="op">*</span>df[<span class="st">'Height'</span>]</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots()</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a>ax.scatter(df[<span class="st">'Weight'</span>], df[<span class="st">'Height'</span>])</span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Weight (kg)'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Height (cm)'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a>df[[<span class="st">'Weight'</span>, <span class="st">'Height'</span>]].describe()</span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a>show()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>           Weight      Height
count  100.000000  100.000000
mean    69.300000  170.357800
std     11.957139    7.204631
min     49.950000  152.400000
25%     58.837500  165.100000
50%     64.125000  170.180000
75%     81.112500  175.895000
max     90.900000  182.880000</code></pre>
</div>
<figure><img src="fig/01-clustering-intro-rendered-unnamed-chunk-2-1.png" width="672" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
Looking at the data, one might expect that there are two distinct
groups, visually identified as two clouds separated e.g. by a vertical
line at Weight <span class="math inline">\(\approx\)</span> 70 (kg). A
consequence is that the mean value of 69.3 kg (which was calculated over
all samples) should better be replaced by two mean values, one for each
of the clouds. Visually, these can be estimated at around 60 and 80 kg.
</p>
<p>We can make this even clearer by looking at the two individual
distributions.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(ncols<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>ax[<span class="dv">0</span>].hist(df[<span class="st">'Weight'</span>], bins<span class="op">=</span><span class="dv">20</span>)<span class="op">;</span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>ax[<span class="dv">0</span>].set_xlabel(<span class="st">'Weight'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>ax[<span class="dv">0</span>].set_ylabel(<span class="st">'Count'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>ax[<span class="dv">1</span>].hist(df[<span class="st">'Height'</span>], bins<span class="op">=</span><span class="dv">12</span>)<span class="op">;</span></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlabel(<span class="st">'Height'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)<span class="op">;</span></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/01-clustering-intro-rendered-unnamed-chunk-3-3.png" width="672" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
The Weight histogram shows two distributions (at the chosen number of
bins) which now also points to the two mean values as guessed above. The
Height histogram is at least not compatible with the assumption of a
normal distribution as would be expected for a typically noisy variable.
</p>
<p style="text-align: justify;">
Thus, visual inspection suggests to analyse the data in terms of more
than one underlying distribution. The automated assignment of data
points to distinct groups is called clustering.
</p>
<p style="text-align: justify;">
We now want to learn to use the Gaussian Mixture Model approach to find
those groups. As we will not provide any labels for the training, this
presents an example of unsupervised machine learning. Algorithms of this
type of machine learning are designed to learn to optimally assign
labels through training. As a result, we will be able to separate a
dataset into groups and be able to predict the labels of new, unlabelled
data.
</p>
</section><section><h2 class="section-heading" id="gaussian-mixture-models">Gaussian Mixture Models<a class="anchor" aria-label="anchor" href="#gaussian-mixture-models"></a></h2>
<hr class="half-width"><p style="text-align: justify;">
A Gaussian Mixture Models (GMM) approach assumes that the data are
composed of two or more normal distributions that may overlap. In a
scatter plot that means that there is more than one centre in the
density distribution of the data (see scatter plot above). The task is
to find the centres and the spread of each distribution in the mixture.
The GMM algorithm thus belongs to the category of (probability) Density
Estimators. Another way of grouping is to find a curve that splits the
plane into two areas.
</p>
<p style="text-align: justify;">
The GMM assumes normally distributed data structure from at least two
sources. Other than that it does not make assumptions about the data.
</p>
<p style="text-align: justify;">
GMM is a parametric learning approach as it optimises the parameters of
a normal distributions, i.e. the mean and the covariance matrix of each
group. It is therefore an example of a model fitting method.
</p>
<p style="text-align: justify;">
As its name suggests, it assumes that the distribution of each group is
normal. If the groups are known to have a non-normal distribution, it
may not be the optimal approach.
</p>
<p style="text-align: justify;">
GMM is one example of clustering or <a href="https://en.wikipedia.org/wiki/Cluster_analysis" class="external-link">cluster
analysis</a>. Whenever we suspect that a data set contains contributions
of qualitatively different types, we can consider doing a cluster
analysis to separate those types. However, this is a vague notion and
clustering is therefore a complex field. We can only provide an
introduction to its basic components. The main point to keep in mind is
that the algorithms provided e.g. by Scikit-learn will always give some
result but that it is not easy to assess the quality of the results.
Scikit-learn has a good <a href="https://scikit-learn.org/stable/modules/clustering.html#c" class="external-link">overview
of clustering methods</a> showing advantages and disadvantages of each.
Here is a link to a readable introduction about the cautious application
and the <a href="https://stke.sciencemag.org/content/9/432/re6.full" class="external-link">pitfalls of
clustering</a>.
</p>
</section><section><h2 class="section-heading" id="work-through-example">Work Through Example<a class="anchor" aria-label="anchor" href="#work-through-example"></a></h2>
<hr class="half-width"><div class="section level3">
<h3 id="creating-test-data"><strong>Creating test data</strong><a class="anchor" aria-label="anchor" href="#creating-test-data"></a></h3>
<p style="text-align: justify;">
Let us create synthetic data for testing of the clustering algorithm. We
do this according to the assumptions of GMM: we create two Gaussian data
sets with different means and different standard distributions and add
them together. For illustration we only use two features.
</p>
<p>The example is adapted from a <a href="https://scikit-learn.org/stable/modules/mixture.html#mixture" class="external-link">Scikit-learn
example</a>. It uses the concept of <a href="https://datascienceplus.com/understanding-the-covariance-matrix/" class="external-link">covariance
matrix</a> which is the extension of variance (or standard deviation) to
multivariate datasets.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>m_features <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="co"># Seed the random number generator</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>RANDOM_NUMBER <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>seed(RANDOM_NUMBER)</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a><span class="co"># Data set 1, centered at (20, 20)</span></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>mean_11 <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>mean_12 <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>gaussian_1 <span class="op">=</span> randn(n_samples, m_features) <span class="op">+</span> array([mean_11, mean_12])</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a><span class="co"># Data set 2, zero centered and stretched with covariance matrix C</span></span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a>C <span class="op">=</span> array([[<span class="dv">1</span>, <span class="op">-</span><span class="fl">0.7</span>], [<span class="fl">3.5</span>, <span class="fl">.7</span>]])</span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a>gaussian_2 <span class="op">=</span> dot(randn(n_samples, m_features), C)</span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" tabindex="-1"></a><span class="co"># Concatenate the two Gaussians to obtain the training data set</span></span>
<span id="cb5-22"><a href="#cb5-22" tabindex="-1"></a>X_train <span class="op">=</span> vstack([gaussian_1, gaussian_2])</span>
<span id="cb5-23"><a href="#cb5-23" tabindex="-1"></a></span>
<span id="cb5-24"><a href="#cb5-24" tabindex="-1"></a><span class="bu">print</span>(X_train.shape)</span>
<span id="cb5-25"><a href="#cb5-25" tabindex="-1"></a></span>
<span id="cb5-26"><a href="#cb5-26" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots()</span>
<span id="cb5-27"><a href="#cb5-27" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" tabindex="-1"></a>ax.scatter(X_train[:, <span class="dv">0</span>], X_train[:, <span class="dv">1</span>])<span class="op">;</span></span>
<span id="cb5-29"><a href="#cb5-29" tabindex="-1"></a></span>
<span id="cb5-30"><a href="#cb5-30" tabindex="-1"></a>show()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(1000, 2)</code></pre>
</div>
<figure><img src="fig/01-clustering-intro-rendered-unnamed-chunk-4-5.png" width="672" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
The scatter plot showes that this method allows the adjustment of the
centres of the distributions as well as the elliptic shape of the
distribution.
</p>
<p style="text-align: justify;">
Now we fit a GMM. Note that the GMM needs to be told how many components
one wants to fit. Modifications that estimate the optimal number of
components exist but we will restrict the demonstration to the method
that directly sets the number.
</p>
<p style="text-align: justify;">
Analogous to the classifier in supervised learning, we instantiate the
model from the imported class <code>GaussianMixture</code>. The
instantiation takes the number of independent data sets (clusters) as an
argument. By default, the classifier tries to fit the full covariance
matrix of each group. The fitting is done using the method
<code>fit</code>.
</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="im">from</span> sklearn.mixture <span class="im">import</span> GaussianMixture</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="co"># Fit a Gaussian Mixture Model with two components</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>components <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>clf <span class="op">=</span> GaussianMixture(n_components<span class="op">=</span>components)</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a>clf.fit(X_train)</span></code></pre>
</div>
<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>GaussianMixture(n_components=2)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">GaussianMixture</label><div class="sk-toggleable__content"><pre>GaussianMixture(n_components=2)</pre></div>
</div></div></div>
</div>
<p style="text-align: justify;">
After the fitting of the model, we first create a meshgrid of the
(two-dimensional) state space. For each point in this state space, we
obtain the predicted scores using the method
<code>.score_samples</code>. These are the weighted logarithmic
probabilities which show the predicted distribution of points in the
state space.
</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>resolution <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>vec_a <span class="op">=</span> linspace(<span class="op">-</span><span class="fl">60.</span>, <span class="fl">80.</span>, resolution)</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>vec_b <span class="op">=</span> linspace(<span class="op">-</span><span class="fl">40.</span>, <span class="fl">50.</span>, resolution)</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>grid_a, grid_b <span class="op">=</span> meshgrid(vec_a, vec_b)</span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>XY_statespace <span class="op">=</span> c_[grid_a.ravel(), grid_b.ravel()]</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>Z_score <span class="op">=</span> clf.score_samples(XY_statespace)</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>Z_s <span class="op">=</span> Z_score.reshape(grid_a.shape)</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a><span class="bu">print</span>(Z_s.shape)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(100, 100)</code></pre>
</div>
<p style="text-align: justify;">
Now we can display the predicted scores as a contour plot. Typically,
the negative log-likelihood or <a href="https://scikit-learn.org/stable/auto_examples/mixture/plot_gmm_pdf.html?highlight=lognorm" class="external-link">density
estimation</a> is used for this. In this case, the highest probabilities
are shown as a landscape with two minima.
</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>cax <span class="op">=</span> ax.contour(grid_a, grid_b, <span class="op">-</span>Z_s,</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>           norm<span class="op">=</span>LogNorm(vmin<span class="op">=</span><span class="fl">1.0</span>, vmax<span class="op">=</span><span class="fl">1000.0</span>),</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>           levels<span class="op">=</span>logspace(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">10</span>),</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>           cmap<span class="op">=</span><span class="st">'magma'</span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>          )</span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>fig.colorbar(cax)<span class="op">;</span></span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a>ax.scatter(X_train[:, <span class="dv">0</span>], X_train[:, <span class="dv">1</span>], <span class="fl">.8</span>)</span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>title(<span class="st">'Negative log-likelihood of Prediction'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>axis(<span class="st">'tight'</span>)<span class="op">;</span></span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/01-clustering-intro-rendered-unnamed-chunk-7-7.png" width="768" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>You can change the number of components to see the impact it has on
the result. E.g. picking 3 components:</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>clf_3 <span class="op">=</span> GaussianMixture(n_components<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>clf_3.fit(X_train)</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>Z_score_3 <span class="op">=</span> clf_3.score_samples(XY_statespace)</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>Z_s_3 <span class="op">=</span> Z_score_3.reshape(grid_a.shape)</span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a>cax <span class="op">=</span> ax.contour(grid_a, grid_b, <span class="op">-</span>Z_s_3,</span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a>           norm<span class="op">=</span>LogNorm(vmin<span class="op">=</span><span class="fl">1.0</span>, vmax<span class="op">=</span><span class="fl">1000.0</span>),</span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a>           levels<span class="op">=</span>logspace(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">10</span>),</span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a>           cmap<span class="op">=</span><span class="st">'magma'</span></span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a>          )</span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a>fig.colorbar(cax)<span class="op">;</span></span>
<span id="cb11-18"><a href="#cb11-18" tabindex="-1"></a></span>
<span id="cb11-19"><a href="#cb11-19" tabindex="-1"></a>title(<span class="st">'Negative log-likelihood (3 components)'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb11-20"><a href="#cb11-20" tabindex="-1"></a>axis(<span class="st">'tight'</span>)<span class="op">;</span></span>
<span id="cb11-21"><a href="#cb11-21" tabindex="-1"></a></span>
<span id="cb11-22"><a href="#cb11-22" tabindex="-1"></a>show()</span></code></pre>
</div>
<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>GaussianMixture(n_components=3)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">GaussianMixture</label><div class="sk-toggleable__content"><pre>GaussianMixture(n_components=3)</pre></div>
</div></div></div>
</div>
<figure><img src="fig/01-clustering-intro-rendered-unnamed-chunk-8-9.png" width="768" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
For the choice of 3 components it does not lead to a probability
distribution with 3 distinct maxima. This is because two of the maxima
coincide or at least nearly coincide.
</p>
<p style="text-align: justify;">
In our example, the choice of 2 components is very obvious because as
done above, we could visualise the complete state space and there was a
visually discernible structure in the data. In high-dimensional data the
task is difficult and while methods exist to automatically find the <a href="https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set" class="external-link">optimal
number of components for some clustering methods</a>, the success of
these depends very much on the problem.
</p>
</div>
<div class="section level3">
<h3 id="getting-optimal-model-parameters"><strong>Getting optimal model parameters</strong><a class="anchor" aria-label="anchor" href="#getting-optimal-model-parameters"></a></h3>
<p style="text-align: justify;">
Now that the estimator is fitted, we can obtain the optimal parameters
for the fitted components. They are stored in the model attributes. We
can extract (i) the <code>.weights_</code>, the share of each of the
components (Gaussians) in the mixture; (ii) the <code>.means_</code>,
the coordinates of the mean values; and (iii)
<code>.covariances_</code>, the covariance matrix of each component.
</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>components <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>clf <span class="op">=</span> GaussianMixture(n_components<span class="op">=</span>components)<span class="op">;</span></span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>clf.fit(X_train)</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Model Weights: '</span>)</span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a><span class="bu">print</span>(clf.weights_)</span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a><span class="bu">print</span>(<span class="st">''</span>)</span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Mean coordinates: '</span>)</span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a><span class="bu">print</span>(clf.means_)</span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a><span class="bu">print</span>(<span class="st">''</span>)</span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Covariance Matrices: '</span>)</span>
<span id="cb12-15"><a href="#cb12-15" tabindex="-1"></a><span class="bu">print</span>(clf.covariances_)</span></code></pre>
</div>
<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-3" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>GaussianMixture(n_components=2)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" checked><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">GaussianMixture</label><div class="sk-toggleable__content"><pre>GaussianMixture(n_components=2)</pre></div>
</div></div></div>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Model Weights:
[0.5 0.5]

Mean coordinates:
[[ 2.00467649e+01  2.00308601e+01]
 [ 1.10681138e-01 -6.87868023e-03]]

Covariance Matrices:
[[[ 0.95442218 -0.06641459]
  [-0.06641459  0.97019156]]

 [[13.78557368  1.81677876]
  [ 1.81677876  1.04931994]]]</code></pre>
</div>
<p style="text-align: justify;">
The fit returns a model where the two components have equal weight. The
means and covariance matrices can be compared directly to the values
chosen to create the data. They are not identical but good estimates are
obtained from a fit to 500 data points in each group.
</p>
</div>
<div class="section level3">
<h3 id="create-data-from-optimal-model"><strong>Create data from optimal model</strong><a class="anchor" aria-label="anchor" href="#create-data-from-optimal-model"></a></h3>
<p style="text-align: justify;">
The result of the fitting are the parameters for two Gaussian
distributions with two features each. These parameters can be used to
create further model data with the same characteristics. In our
demonstration we know the original sources but if the parameters are
obtained from experimental or clinical data, it is useful to visualise
the predicted distributions using as many samples as necessary.
</p>
<p>If we know the mean and the covariance matrix of a Gaussian, the
function <code>multivariate_normal</code> can be used to create data
from that Gaussian.</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>model1_mean, model2_mean <span class="op">=</span> clf.means_[<span class="dv">0</span>], clf.means_[<span class="dv">1</span>]</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>model1_cov, model2_cov <span class="op">=</span>  clf.covariances_[<span class="dv">0</span>], clf.covariances_[<span class="dv">1</span>]</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a>samples <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a>model1_data <span class="op">=</span> multivariate_normal(model1_mean, model1_cov, samples)</span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a>model2_data <span class="op">=</span> multivariate_normal(model2_mean, model2_cov, samples)</span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots()</span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a>ax.scatter(model1_data[:, <span class="dv">0</span>], model1_data[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'b'</span>)<span class="op">;</span></span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a>ax.scatter(model2_data[:, <span class="dv">0</span>], model2_data[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'r'</span>)<span class="op">;</span></span>
<span id="cb14-13"><a href="#cb14-13" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/01-clustering-intro-rendered-unnamed-chunk-10-11.png" width="672" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure></div>
<div class="section level3">
<h3 id="predicting-labels"><strong>Predicting Labels</strong><a class="anchor" aria-label="anchor" href="#predicting-labels"></a></h3>
Now we can apply what we have discussed in supervised machine learning
and use the trained model to predict.
<p style="text-align: justify;">
We can get the predictions of the group for new data. Here, for
simplicity, we create test data from the same distribution as the train
data. The label is obtained from the method <code>.predict</code>.
</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>m_features <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a><span class="co"># Seed the random number generator</span></span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>RANDOM_NUMBER <span class="op">=</span> <span class="dv">111</span></span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a>seed(RANDOM_NUMBER)</span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a><span class="co"># Data set 1, centered at (20, 20)</span></span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a>mean_11 <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a>mean_12 <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a></span>
<span id="cb15-13"><a href="#cb15-13" tabindex="-1"></a>gaussian_1 <span class="op">=</span> randn(n_samples, m_features) <span class="op">+</span> array([mean_11, mean_12])</span>
<span id="cb15-14"><a href="#cb15-14" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" tabindex="-1"></a></span>
<span id="cb15-16"><a href="#cb15-16" tabindex="-1"></a><span class="co"># Data set 2, zero centered and stretched with covariance matrix C</span></span>
<span id="cb15-17"><a href="#cb15-17" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" tabindex="-1"></a>C <span class="op">=</span> array([[<span class="dv">1</span>, <span class="op">-</span><span class="fl">0.7</span>], [<span class="fl">3.5</span>, <span class="fl">.7</span>]])</span>
<span id="cb15-19"><a href="#cb15-19" tabindex="-1"></a></span>
<span id="cb15-20"><a href="#cb15-20" tabindex="-1"></a>gaussian_2 <span class="op">=</span> dot(randn(n_samples, m_features), C)</span>
<span id="cb15-21"><a href="#cb15-21" tabindex="-1"></a></span>
<span id="cb15-22"><a href="#cb15-22" tabindex="-1"></a></span>
<span id="cb15-23"><a href="#cb15-23" tabindex="-1"></a><span class="co"># Concatenate the two Gaussians to obtain the training data set</span></span>
<span id="cb15-24"><a href="#cb15-24" tabindex="-1"></a>X_test <span class="op">=</span> vstack([gaussian_1, gaussian_2])</span>
<span id="cb15-25"><a href="#cb15-25" tabindex="-1"></a></span>
<span id="cb15-26"><a href="#cb15-26" tabindex="-1"></a></span>
<span id="cb15-27"><a href="#cb15-27" tabindex="-1"></a><span class="co"># Predict group</span></span>
<span id="cb15-28"><a href="#cb15-28" tabindex="-1"></a>y_test <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb15-29"><a href="#cb15-29" tabindex="-1"></a></span>
<span id="cb15-30"><a href="#cb15-30" tabindex="-1"></a><span class="bu">print</span>(y_test)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]</code></pre>
</div>
<p style="text-align: justify;">
For simplicity, fit and predict can be combined with the
<code>.fit_predict</code> method to directly get the labels for each
sample. Here is an example where we fit the model to the test data and
directly extract their predicted labels.
</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a>components <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>clf_2 <span class="op">=</span> GaussianMixture(n_components<span class="op">=</span>components, covariance_type<span class="op">=</span><span class="st">'full'</span>)</span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a>labels <span class="op">=</span> clf_2.fit_predict(X_test)</span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a><span class="bu">print</span>(labels)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]</code></pre>
</div>
<p style="text-align: justify;">
The probabilities of the predictions are obtained from the method
<code>.predict_proba</code>. In this case, all probabilities are 0 and 1
respectively. The model is sure about their group signature.
</p>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>y_proba <span class="op">=</span> clf.predict_proba(X_test)</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots()</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a>ax.hist(y_proba, bins<span class="op">=</span><span class="dv">10</span>)<span class="op">;</span></span>
<span id="cb19-6"><a href="#cb19-6" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/01-clustering-intro-rendered-unnamed-chunk-13-13.png" width="672" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
The <code>.sample_</code> method produces individual samples from the
trained model. It takes the number of required samples as an input
argument and yields the sample values as well as the group for each
sample. Samples for each group are given with probability according to
the group weights.
</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>samples <span class="op">=</span> clf.sample(<span class="dv">5</span>)</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a><span class="bu">print</span>(samples[<span class="dv">0</span>])</span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a><span class="bu">print</span>(<span class="st">''</span>)</span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a><span class="bu">print</span>(samples[<span class="dv">1</span>])</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[[20.06076245 20.69983729]
 [21.67317947 21.86459529]
 [ 4.90658144 -0.99981225]
 [ 4.74232451  0.2655483 ]
 [ 0.92148265  2.32782549]]

[0 0 1 1 1]</code></pre>
</div>
<p>We can now redo the example with two distributions that lie closer
together, i.e. making the clustering task harder.</p>
<div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a>m_features <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a><span class="co"># Seed the random number generator</span></span>
<span id="cb22-5"><a href="#cb22-5" tabindex="-1"></a>RANDOM_NUMBER <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb22-6"><a href="#cb22-6" tabindex="-1"></a>seed(RANDOM_NUMBER)</span>
<span id="cb22-7"><a href="#cb22-7" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" tabindex="-1"></a><span class="co"># Data set 1, centered at (20, 20)</span></span>
<span id="cb22-9"><a href="#cb22-9" tabindex="-1"></a></span>
<span id="cb22-10"><a href="#cb22-10" tabindex="-1"></a>mean_11 <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb22-11"><a href="#cb22-11" tabindex="-1"></a>mean_12 <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb22-12"><a href="#cb22-12" tabindex="-1"></a></span>
<span id="cb22-13"><a href="#cb22-13" tabindex="-1"></a>gaussian_1 <span class="op">=</span> randn(n_samples, m_features) <span class="op">+</span> array([mean_11, mean_12])</span>
<span id="cb22-14"><a href="#cb22-14" tabindex="-1"></a></span>
<span id="cb22-15"><a href="#cb22-15" tabindex="-1"></a></span>
<span id="cb22-16"><a href="#cb22-16" tabindex="-1"></a><span class="co"># Data set 2, zero centered and stretched with covariance matrix C</span></span>
<span id="cb22-17"><a href="#cb22-17" tabindex="-1"></a></span>
<span id="cb22-18"><a href="#cb22-18" tabindex="-1"></a>C <span class="op">=</span> array([[<span class="dv">1</span>, <span class="op">-</span><span class="fl">0.7</span>], [<span class="fl">3.5</span>, <span class="fl">.7</span>]])</span>
<span id="cb22-19"><a href="#cb22-19" tabindex="-1"></a></span>
<span id="cb22-20"><a href="#cb22-20" tabindex="-1"></a>gaussian_2 <span class="op">=</span> dot(randn(n_samples, m_features), C)</span>
<span id="cb22-21"><a href="#cb22-21" tabindex="-1"></a></span>
<span id="cb22-22"><a href="#cb22-22" tabindex="-1"></a></span>
<span id="cb22-23"><a href="#cb22-23" tabindex="-1"></a><span class="co"># Concatenate the two Gaussians to obtain the training data set</span></span>
<span id="cb22-24"><a href="#cb22-24" tabindex="-1"></a>X_train <span class="op">=</span> vstack([gaussian_1, gaussian_2])</span>
<span id="cb22-25"><a href="#cb22-25" tabindex="-1"></a></span>
<span id="cb22-26"><a href="#cb22-26" tabindex="-1"></a><span class="bu">print</span>(X_train.shape)</span>
<span id="cb22-27"><a href="#cb22-27" tabindex="-1"></a></span>
<span id="cb22-28"><a href="#cb22-28" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots()</span>
<span id="cb22-29"><a href="#cb22-29" tabindex="-1"></a></span>
<span id="cb22-30"><a href="#cb22-30" tabindex="-1"></a>ax.scatter(X_train[:, <span class="dv">0</span>], X_train[:, <span class="dv">1</span>])<span class="op">;</span></span>
<span id="cb22-31"><a href="#cb22-31" tabindex="-1"></a></span>
<span id="cb22-32"><a href="#cb22-32" tabindex="-1"></a>show()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(1000, 2)</code></pre>
</div>
<figure><img src="fig/01-clustering-intro-rendered-unnamed-chunk-15-15.png" width="672" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><div class="codewrapper sourceCode" id="cb24">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a>components <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" tabindex="-1"></a>clf2 <span class="op">=</span> GaussianMixture(n_components<span class="op">=</span>components)</span>
<span id="cb24-4"><a href="#cb24-4" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" tabindex="-1"></a>clf2.fit(X_train)</span>
<span id="cb24-6"><a href="#cb24-6" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" tabindex="-1"></a>resolution <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb24-8"><a href="#cb24-8" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" tabindex="-1"></a>vec_a <span class="op">=</span> linspace(<span class="op">-</span><span class="fl">40.</span>, <span class="fl">60.</span>, resolution)</span>
<span id="cb24-10"><a href="#cb24-10" tabindex="-1"></a>vec_b <span class="op">=</span> linspace(<span class="op">-</span><span class="fl">20.</span>, <span class="fl">30.</span>, resolution)</span>
<span id="cb24-11"><a href="#cb24-11" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" tabindex="-1"></a>grid_a, grid_b <span class="op">=</span> meshgrid(vec_a, vec_b)</span>
<span id="cb24-13"><a href="#cb24-13" tabindex="-1"></a></span>
<span id="cb24-14"><a href="#cb24-14" tabindex="-1"></a>XY_statespace <span class="op">=</span> c_[grid_a.ravel(), grid_b.ravel()]</span>
<span id="cb24-15"><a href="#cb24-15" tabindex="-1"></a></span>
<span id="cb24-16"><a href="#cb24-16" tabindex="-1"></a>Z_score <span class="op">=</span> clf2.score_samples(XY_statespace)</span>
<span id="cb24-17"><a href="#cb24-17" tabindex="-1"></a></span>
<span id="cb24-18"><a href="#cb24-18" tabindex="-1"></a>Z_s <span class="op">=</span> Z_score.reshape(grid_a.shape)</span>
<span id="cb24-19"><a href="#cb24-19" tabindex="-1"></a></span>
<span id="cb24-20"><a href="#cb24-20" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb24-21"><a href="#cb24-21" tabindex="-1"></a></span>
<span id="cb24-22"><a href="#cb24-22" tabindex="-1"></a>cax <span class="op">=</span> ax.contour(grid_a, grid_b, <span class="op">-</span>Z_s,</span>
<span id="cb24-23"><a href="#cb24-23" tabindex="-1"></a>           norm<span class="op">=</span>LogNorm(vmin<span class="op">=</span><span class="fl">1.0</span>, vmax<span class="op">=</span><span class="fl">1000.0</span>),</span>
<span id="cb24-24"><a href="#cb24-24" tabindex="-1"></a>           levels<span class="op">=</span>logspace(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">10</span>),</span>
<span id="cb24-25"><a href="#cb24-25" tabindex="-1"></a>           cmap<span class="op">=</span><span class="st">'magma'</span></span>
<span id="cb24-26"><a href="#cb24-26" tabindex="-1"></a>          )</span>
<span id="cb24-27"><a href="#cb24-27" tabindex="-1"></a></span>
<span id="cb24-28"><a href="#cb24-28" tabindex="-1"></a>fig.colorbar(cax)<span class="op">;</span></span>
<span id="cb24-29"><a href="#cb24-29" tabindex="-1"></a></span>
<span id="cb24-30"><a href="#cb24-30" tabindex="-1"></a>ax.scatter(X_train[:, <span class="dv">0</span>], X_train[:, <span class="dv">1</span>], <span class="fl">.8</span>)</span>
<span id="cb24-31"><a href="#cb24-31" tabindex="-1"></a></span>
<span id="cb24-32"><a href="#cb24-32" tabindex="-1"></a>title(<span class="st">'Negative log-likelihood of Prediction'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb24-33"><a href="#cb24-33" tabindex="-1"></a>axis(<span class="st">'tight'</span>)<span class="op">;</span></span>
<span id="cb24-34"><a href="#cb24-34" tabindex="-1"></a></span>
<span id="cb24-35"><a href="#cb24-35" tabindex="-1"></a>show()</span></code></pre>
</div>
<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-4" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>GaussianMixture(n_components=2)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox" checked><label for="sk-estimator-id-4" class="sk-toggleable__label sk-toggleable__label-arrow">GaussianMixture</label><div class="sk-toggleable__content"><pre>GaussianMixture(n_components=2)</pre></div>
</div></div></div>
</div>
<figure><img src="fig/01-clustering-intro-rendered-unnamed-chunk-16-17.png" width="768" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><div class="codewrapper sourceCode" id="cb25">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Model Weights: '</span>)</span>
<span id="cb25-2"><a href="#cb25-2" tabindex="-1"></a><span class="bu">print</span>(clf2.weights_)</span>
<span id="cb25-3"><a href="#cb25-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">''</span>)</span>
<span id="cb25-4"><a href="#cb25-4" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Mean coordinates: '</span>)</span>
<span id="cb25-6"><a href="#cb25-6" tabindex="-1"></a><span class="bu">print</span>(clf2.means_)</span>
<span id="cb25-7"><a href="#cb25-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">''</span>)</span>
<span id="cb25-8"><a href="#cb25-8" tabindex="-1"></a></span>
<span id="cb25-9"><a href="#cb25-9" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Covariance Matrices: '</span>)</span>
<span id="cb25-10"><a href="#cb25-10" tabindex="-1"></a><span class="bu">print</span>(clf2.covariances_)</span>
<span id="cb25-11"><a href="#cb25-11" tabindex="-1"></a><span class="bu">print</span>(<span class="st">''</span>)</span>
<span id="cb25-12"><a href="#cb25-12" tabindex="-1"></a></span>
<span id="cb25-13"><a href="#cb25-13" tabindex="-1"></a>y_predict <span class="op">=</span> clf2.predict(X_train)</span>
<span id="cb25-14"><a href="#cb25-14" tabindex="-1"></a></span>
<span id="cb25-15"><a href="#cb25-15" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Predicted Labels'</span>)</span>
<span id="cb25-16"><a href="#cb25-16" tabindex="-1"></a><span class="bu">print</span>(y_predict)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Model Weights:
[0.51626883 0.48373117]

Mean coordinates:
[[ 2.02822009  2.0218213 ]
 [ 0.06535904 -0.06576508]]

Covariance Matrices:
[[[ 0.95990893 -0.03850552]
  [-0.03850552  0.94445254]]

 [[14.15940548  1.77380246]
  [ 1.77380246  0.97555916]]]

Predicted Labels
[0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1
 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0
 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 0
 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1
 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0
 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1
 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1
 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1
 1]</code></pre>
</div>
</div>
<div class="section level3">
<h3 id="scoring-of-predictions"><strong>Scoring of Predictions</strong><a class="anchor" aria-label="anchor" href="#scoring-of-predictions"></a></h3>
<p style="text-align: justify;">
Knowing the origin of the data we can now compare the predicted labels
with the true labels (the ground truth) and obtain a scoring. A function
provided by Scikit-learn is the (adjusted or unadjusted) <strong>Rand
index</strong>. It measures the similarity of the predicted and the true
assignments. However, random assignment of labels will (by chance) lead
to a number of correct predictions. To adjust for this fact and ensure
that randomly assigned labels get a scoring close to zero, the function
to use is <code>adjusted_rand_score</code>:
</p>
<div class="codewrapper sourceCode" id="cb27">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.cluster <span class="im">import</span> adjusted_rand_score</span>
<span id="cb27-2"><a href="#cb27-2" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" tabindex="-1"></a>y_true <span class="op">=</span> zeros(<span class="dv">2</span><span class="op">*</span>n_samples)</span>
<span id="cb27-4"><a href="#cb27-4" tabindex="-1"></a>y_true[n_samples:] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb27-5"><a href="#cb27-5" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" tabindex="-1"></a>scoring <span class="op">=</span> adjusted_rand_score(y_true, y_predict)</span>
<span id="cb27-7"><a href="#cb27-7" tabindex="-1"></a></span>
<span id="cb27-8"><a href="#cb27-8" tabindex="-1"></a><span class="bu">print</span>(scoring)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span><span class="fl">0.6174145036659798</span></span></code></pre>
</div>
<p style="text-align: justify;">
The result shows that even though the two distributions are strongly
overlapping, there is still a reasonable score based on the known ground
truth.
</p>
<p style="text-align: justify;">
It is important to remember that the ground truth is typically not
known. There are therefore also measures to score the outcome based on
within-data criteria. See <a href="https://en.wikipedia.org/wiki/Cluster_analysis" class="external-link">internal
evaluation of the wikipedia article</a> for some techniques.
</p>
<p style="text-align: justify;">
In general, the outcome of clustering is not easy to assess with
confidence and specific measures need to be developed based on
additional knowledge about the source of the data.
</p>
</div>
</section><section><h2 class="section-heading" id="application-to-example-data">Application to Example Data<a class="anchor" aria-label="anchor" href="#application-to-example-data"></a></h2>
<hr class="half-width"><p>Let us now apply the GMM approach to the example at the beginning of
the lesson.</p>
<div class="codewrapper sourceCode" id="cb29">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a><span class="im">from</span> pandas <span class="im">import</span> read_csv</span>
<span id="cb29-2"><a href="#cb29-2" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" tabindex="-1"></a>df <span class="op">=</span> read_csv(<span class="st">"data/patients_data.csv"</span>)</span>
<span id="cb29-4"><a href="#cb29-4" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" tabindex="-1"></a>df[<span class="st">'Weight'</span>] <span class="op">=</span> <span class="fl">0.45</span><span class="op">*</span>df[<span class="st">'Weight'</span>]</span>
<span id="cb29-6"><a href="#cb29-6" tabindex="-1"></a>df[<span class="st">'Height'</span>] <span class="op">=</span> <span class="fl">2.54</span><span class="op">*</span>df[<span class="st">'Height'</span>]</span>
<span id="cb29-7"><a href="#cb29-7" tabindex="-1"></a></span>
<span id="cb29-8"><a href="#cb29-8" tabindex="-1"></a>X_train <span class="op">=</span> df[[<span class="st">'Weight'</span>, <span class="st">'Height'</span>]]</span>
<span id="cb29-9"><a href="#cb29-9" tabindex="-1"></a>X_train <span class="op">=</span> X_train.to_numpy()</span>
<span id="cb29-10"><a href="#cb29-10" tabindex="-1"></a></span>
<span id="cb29-11"><a href="#cb29-11" tabindex="-1"></a><span class="bu">print</span>(X_train.shape)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(100, 2)</code></pre>
</div>
<p>Now we can fit the GMM classifier using the suspected number of two
components.</p>
<div class="codewrapper sourceCode" id="cb31">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a>clf <span class="op">=</span> GaussianMixture(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb31-2"><a href="#cb31-2" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" tabindex="-1"></a>clf.fit(X_train)</span>
<span id="cb31-4"><a href="#cb31-4" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" tabindex="-1"></a>resolution <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb31-6"><a href="#cb31-6" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" tabindex="-1"></a>vec_a <span class="op">=</span> linspace(<span class="fl">0.8</span><span class="op">*</span><span class="bu">min</span>(X_train[:,<span class="dv">0</span>]), <span class="fl">1.2</span><span class="op">*</span><span class="bu">max</span>(X_train[:,<span class="dv">0</span>]), resolution)</span>
<span id="cb31-8"><a href="#cb31-8" tabindex="-1"></a>vec_b <span class="op">=</span> linspace(<span class="fl">0.8</span><span class="op">*</span><span class="bu">min</span>(X_train[:,<span class="dv">1</span>]), <span class="fl">1.2</span><span class="op">*</span><span class="bu">max</span>(X_train[:,<span class="dv">1</span>]), resolution)</span>
<span id="cb31-9"><a href="#cb31-9" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" tabindex="-1"></a>grid_a, grid_b <span class="op">=</span> meshgrid(vec_a, vec_b)</span>
<span id="cb31-11"><a href="#cb31-11" tabindex="-1"></a></span>
<span id="cb31-12"><a href="#cb31-12" tabindex="-1"></a>XY_statespace <span class="op">=</span> c_[grid_a.ravel(), grid_b.ravel()]</span>
<span id="cb31-13"><a href="#cb31-13" tabindex="-1"></a></span>
<span id="cb31-14"><a href="#cb31-14" tabindex="-1"></a>Z_score <span class="op">=</span> clf.score_samples(XY_statespace)</span>
<span id="cb31-15"><a href="#cb31-15" tabindex="-1"></a></span>
<span id="cb31-16"><a href="#cb31-16" tabindex="-1"></a>Z_s <span class="op">=</span> Z_score.reshape(grid_a.shape)</span>
<span id="cb31-17"><a href="#cb31-17" tabindex="-1"></a></span>
<span id="cb31-18"><a href="#cb31-18" tabindex="-1"></a></span>
<span id="cb31-19"><a href="#cb31-19" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb31-20"><a href="#cb31-20" tabindex="-1"></a></span>
<span id="cb31-21"><a href="#cb31-21" tabindex="-1"></a>cax <span class="op">=</span> ax.contour(grid_a, grid_b, <span class="op">-</span>Z_s,</span>
<span id="cb31-22"><a href="#cb31-22" tabindex="-1"></a>           norm<span class="op">=</span>LogNorm(vmin<span class="op">=</span><span class="fl">1.0</span>, vmax<span class="op">=</span><span class="fl">1000.0</span>),</span>
<span id="cb31-23"><a href="#cb31-23" tabindex="-1"></a>           levels<span class="op">=</span>logspace(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">10</span>),</span>
<span id="cb31-24"><a href="#cb31-24" tabindex="-1"></a>           cmap<span class="op">=</span><span class="st">'magma'</span></span>
<span id="cb31-25"><a href="#cb31-25" tabindex="-1"></a>          )</span>
<span id="cb31-26"><a href="#cb31-26" tabindex="-1"></a></span>
<span id="cb31-27"><a href="#cb31-27" tabindex="-1"></a>fig.colorbar(cax)<span class="op">;</span></span>
<span id="cb31-28"><a href="#cb31-28" tabindex="-1"></a></span>
<span id="cb31-29"><a href="#cb31-29" tabindex="-1"></a>ax.scatter(X_train[:, <span class="dv">0</span>], X_train[:, <span class="dv">1</span>], <span class="fl">.8</span>)</span>
<span id="cb31-30"><a href="#cb31-30" tabindex="-1"></a></span>
<span id="cb31-31"><a href="#cb31-31" tabindex="-1"></a>title(<span class="st">'Negative log-likelihood of Prediction'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb31-32"><a href="#cb31-32" tabindex="-1"></a>axis(<span class="st">'tight'</span>)<span class="op">;</span></span>
<span id="cb31-33"><a href="#cb31-33" tabindex="-1"></a></span>
<span id="cb31-34"><a href="#cb31-34" tabindex="-1"></a>show()</span></code></pre>
</div>
<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-5" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>GaussianMixture(n_components=2)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox" checked><label for="sk-estimator-id-5" class="sk-toggleable__label sk-toggleable__label-arrow">GaussianMixture</label><div class="sk-toggleable__content"><pre>GaussianMixture(n_components=2)</pre></div>
</div></div></div>
</div>
<figure><img src="fig/01-clustering-intro-rendered-unnamed-chunk-20-19.png" width="768" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
These predictions can now be compared with labels in the data, for
example the Gender. To check the outcome of the fitted model versus the
gender, we obtain the predicted labels from the model. We can compare
this with the Gender labels in the data:
</p>
<div class="codewrapper sourceCode" id="cb32">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" tabindex="-1"></a>y_predict <span class="op">=</span> clf.predict(X_train)</span>
<span id="cb32-2"><a href="#cb32-2" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" tabindex="-1"></a>gender_boolean <span class="op">=</span> df[<span class="st">'Gender'</span>] <span class="op">==</span> <span class="st">'Female'</span></span>
<span id="cb32-4"><a href="#cb32-4" tabindex="-1"></a></span>
<span id="cb32-5"><a href="#cb32-5" tabindex="-1"></a>y_gender <span class="op">=</span> gender_boolean.to_numpy()</span>
<span id="cb32-6"><a href="#cb32-6" tabindex="-1"></a></span>
<span id="cb32-7"><a href="#cb32-7" tabindex="-1"></a>scoring <span class="op">=</span> adjusted_rand_score(y_gender, y_predict)</span>
<span id="cb32-8"><a href="#cb32-8" tabindex="-1"></a></span>
<span id="cb32-9"><a href="#cb32-9" tabindex="-1"></a><span class="bu">print</span>(scoring)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span><span class="fl">1.0</span></span></code></pre>
</div>
<p>In this case, the predictions from the GMM coincide 100 % with the
gender label in the data. The outcome is therefore perfect in both
cases.</p>
<p>We can also compare the predictions with the smoker labels:</p>
<div class="codewrapper sourceCode" id="cb34">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" tabindex="-1"></a>y_smoker <span class="op">=</span> df[<span class="st">'Smoker'</span>]</span>
<span id="cb34-2"><a href="#cb34-2" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" tabindex="-1"></a>scoring <span class="op">=</span> adjusted_rand_score(y_smoker, y_predict)</span>
<span id="cb34-4"><a href="#cb34-4" tabindex="-1"></a></span>
<span id="cb34-5"><a href="#cb34-5" tabindex="-1"></a><span class="bu">print</span>(scoring)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span><span class="fl">0.039367492745118096</span></span></code></pre>
</div>
<p>This result shows that the GMM labelling is arbitrary when compared
the smoker labels in the data.</p>
<p>From the trained model we create the individual predicted
distributions for each group.</p>
<div class="codewrapper sourceCode" id="cb36">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" tabindex="-1"></a>group1_mean <span class="op">=</span> clf.means_[<span class="dv">0</span>]</span>
<span id="cb36-2"><a href="#cb36-2" tabindex="-1"></a>group1_cov  <span class="op">=</span> clf.covariances_[<span class="dv">0</span>]</span>
<span id="cb36-3"><a href="#cb36-3" tabindex="-1"></a></span>
<span id="cb36-4"><a href="#cb36-4" tabindex="-1"></a>group2_mean <span class="op">=</span> clf.means_[<span class="dv">1</span>]</span>
<span id="cb36-5"><a href="#cb36-5" tabindex="-1"></a>group2_cov  <span class="op">=</span> clf.covariances_[<span class="dv">1</span>]</span>
<span id="cb36-6"><a href="#cb36-6" tabindex="-1"></a></span>
<span id="cb36-7"><a href="#cb36-7" tabindex="-1"></a>samples <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb36-8"><a href="#cb36-8" tabindex="-1"></a></span>
<span id="cb36-9"><a href="#cb36-9" tabindex="-1"></a></span>
<span id="cb36-10"><a href="#cb36-10" tabindex="-1"></a>group1_data <span class="op">=</span> multivariate_normal(group1_mean, group1_cov, samples)</span>
<span id="cb36-11"><a href="#cb36-11" tabindex="-1"></a>group2_data <span class="op">=</span> multivariate_normal(group2_mean, group2_cov, samples)</span>
<span id="cb36-12"><a href="#cb36-12" tabindex="-1"></a></span>
<span id="cb36-13"><a href="#cb36-13" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(ncols<span class="op">=</span><span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb36-14"><a href="#cb36-14" tabindex="-1"></a></span>
<span id="cb36-15"><a href="#cb36-15" tabindex="-1"></a>ax[<span class="dv">1</span>].scatter(group1_data[:, <span class="dv">0</span>], group1_data[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'r'</span>)<span class="op">;</span></span>
<span id="cb36-16"><a href="#cb36-16" tabindex="-1"></a>ax[<span class="dv">1</span>].scatter(group2_data[:, <span class="dv">0</span>], group2_data[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'b'</span>)<span class="op">;</span></span>
<span id="cb36-17"><a href="#cb36-17" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlabel(<span class="st">'Height'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb36-18"><a href="#cb36-18" tabindex="-1"></a></span>
<span id="cb36-19"><a href="#cb36-19" tabindex="-1"></a>ax[<span class="dv">0</span>].scatter(df[<span class="st">'Weight'</span>], df[<span class="st">'Height'</span>])<span class="op">;</span></span>
<span id="cb36-20"><a href="#cb36-20" tabindex="-1"></a>ax[<span class="dv">0</span>].set_xlabel(<span class="st">'Height'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb36-21"><a href="#cb36-21" tabindex="-1"></a>ax[<span class="dv">0</span>].set_ylabel(<span class="st">'Weight'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb36-22"><a href="#cb36-22" tabindex="-1"></a></span>
<span id="cb36-23"><a href="#cb36-23" tabindex="-1"></a>fig.suptitle(<span class="st">'Scatter plot from Data (left) and Model (right)'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)<span class="op">;</span></span>
<span id="cb36-24"><a href="#cb36-24" tabindex="-1"></a></span>
<span id="cb36-25"><a href="#cb36-25" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/01-clustering-intro-rendered-unnamed-chunk-23-21.png" width="1152" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure></section><section><h2 class="section-heading" id="exercises">Exercises<a class="anchor" aria-label="anchor" href="#exercises"></a></h2>
<hr class="half-width"><div id="end-of-chapter-exercises" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="end-of-chapter-exercises" class="callout-inner">
<h3 class="callout-title">End of chapter Exercises</h3>
<div class="callout-content">
<p>Create the training and prediction workflow as above for a data set
with two other features, namely: Diastole and Systole values from the
‘patients_data.csv’ file.</p>
<ol style="list-style-type: decimal"><li><p>Extract the Diastole and Systole columns.</p></li>
<li><p>Use the data to fit a Gaussian model with 2 components and create
a state space contour plot of the negative log likelihood with scattered
data superimposed.</p></li>
<li><p>Extract the model weights, the means of the two Gaussians and
their corresponding covariance matrices.</p></li>
<li><p>Calculate the adjusted random score for the labels ‘gender’ and
‘smoker’ in the data to estimate whether these have som overlap with the
model fit.</p></li>
<li><p>Compare the original scatter plot versus the model generated
scatter plot. Use a total of 100 samples for the model generated data
and distribute them according to the model weights.</p></li>
<li><p>Repeat the plot multiple times to see how the degree of overlap
in the model output changes with each choice of samples from the fitted
distribution.</p></li>
<li><p>Create corresponding histograms of the Diastolic and Systolic
blood pressure values from data and model. Try to guess where the
differences in appearance come from.</p></li>
</ol><p style="text-align: justify;">
The data show systematic gaps in the histogram meaning that some values
do not occur (integer values only). In contrast, the model data from the
random number generator can take any value. Therefore the counts per bin
are generally lower for the model.
</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">
  Solutions are provided after assignments are marked.
  </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">

</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul><li>The automated assignment of data points to distinct groups is called
<code>clustering</code>.</li>
<li>Gaussian Mixture Models (GMM) is one example of cluster
analysis.</li>
<li>
<code>.fit</code>, <code>..score_samples</code> and
<code>.predict</code> are some of the key methods in GMM
clustering.</li>
<li>
<code>adjusted_rand_score</code> method randomly assigns labels for
prediction scoring.</li>
</ul></div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></div> <!-- / div.lesson-content -->
    </main><!-- / main#main-content.main-content --><nav class="bottom-pagination mx-md-4" aria-label="Previous and Next Chapter"><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="index.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="02-clustering-image.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="index.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Home
        </a>
        <a class="chapter-link float-end" href="02-clustering-image.html" rel="next">
          Next: Clustering Images...
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
    </nav></div> <!-- / div.primary-content.col-xs-12 -->
<!-- END:   inst/pkgdown/templates/content-instructor.html-->

      </div><!--/div.row-->
      		<footer class="row footer mx-md-3"><hr><div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/01-clustering-intro.Rmd" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/carpentries/workbench-template-md/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/carpentries/workbench-template-md/" class="external-link">Source</a></p>
				<p><a href="https://github.com/carpentries/workbench-template-md/blob/main/CITATION" class="external-link">Cite</a> | <a href="mailto:team@carpentries.org">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/69aaefee46a17928e2a1694825599e169b9793e3" class="external-link">sandpaper (0.16.10)</a>, <a href="https://github.com/carpentries/pegboard/tree/bad0be19a12f0c6545801b276ddf26c945f8bfd1" class="external-link">pegboard (0.7.7)</a>, and <a href="https://github.com/milanmlft/varnish/tree/milanmlft/sticky-sidebar" class="external-link">varnish (1.0.3.9000)</a></p>
			</div>
		</footer></div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://carpentries.github.io/workbench-template-md/01-clustering-intro.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "Clustering Introduction",
  "creativeWorkStatus": "active",
  "url": "https://carpentries.github.io/workbench-template-md/01-clustering-intro.html",
  "identifier": "https://carpentries.github.io/workbench-template-md/01-clustering-intro.html",
  "dateCreated": "2022-07-05",
  "dateModified": "2025-01-27",
  "datePublished": "2025-01-27"
}

  </script><script>
		feather.replace();
	</script></body></html><!-- END:   inst/pkgdown/templates/layout.html-->

